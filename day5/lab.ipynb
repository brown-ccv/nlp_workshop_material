{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "### Using the corpus provided in the code below, prepare four matrices: \n",
    "1. Unigram count matrix. \n",
    "2. Bigram count matrix. \n",
    "3. Unigram TFIDF matrix. \n",
    "4. Bigram TFIDF matrix.\n",
    "#### Make sure you remove stopwords (use `stop_words='english'` when you construct your matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', \n",
    "                                      shuffle=True, \n",
    "                                      random_state=1, \n",
    "                                      remove=('headers', 'footers', 'quotes'))\n",
    "print(len(newsgroups_train.data))\n",
    "print(newsgroups_train.data[0])\n",
    "corpus = newsgroups_train.data[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 \n",
    "### Prepare four LDA models: one for each of the matrices from Exercise 1. Each LDA model should have 10 topics. Set `random_state=0` so results are consistent across the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "### Using the function given below, print the top 10 words for the LDA models you trained in Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "import numpy as np\n",
    "\n",
    "def display_topics(model, vocab, n_top_words=10):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print('Topic ' + str(topic_idx) + ':')\n",
    "        print('|'.join([vocab[i] for i in np.argsort(topic)[:-n_top_words-1:-1]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4\n",
    "### Pick one input matrix and do some text normalization, experiment with parameters in CountVectorizer() or TfidfVectorizer(), and experiment with different numbers of topics to try to learn more coherent topics. (Check if the topics make sense by looking at the output of `display_topics()` on your models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
